{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HwiTran/Natural-Language-Processing-Course/blob/main/Week_5_Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install portalocker'>=2.0.0'\n",
        "!pip install torchdata\n",
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCNJf06zkueG",
        "outputId": "003b34da-503c-41cb-e202-f7115e032eb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting portalocker>=2.0.0\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: portalocker\n",
            "Successfully installed portalocker-2.8.2\n",
            "Requirement already satisfied: torchdata in /usr/local/lib/python3.10/dist-packages (0.7.1)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.31.0)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2->torchdata)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2->torchdata) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2->torchdata) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Collecting huggingface-hub>=0.21.2 (from datasets)\n",
            "  Downloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, huggingface-hub, datasets\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "Successfully installed datasets-2.19.1 dill-0.3.8 huggingface-hub-0.23.0 multiprocess-0.70.16 xxhash-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download de_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkFvFKtg1xLh",
        "outputId": "1b1f5368-0aea-46d5-8a68-b55f1d723705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting de-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from de-core-news-sm==3.7.0) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.1)\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Demonstration on Transformer architecture\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "9F77geblbJU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import os\n",
        "from tempfile import TemporaryDirectory\n",
        "from typing import Tuple\n",
        "\n",
        "import numpy as np\n",
        "import random, spacy, datasets"
      ],
      "metadata": {
        "id": "BxtfmDYIcWWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import torchtext\n",
        "from torch.utils.data import dataset"
      ],
      "metadata": {
        "id": "utI1a2c-cXqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word embedding"
      ],
      "metadata": {
        "id": "hBnKN1EzU72C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Embedding(nn.Module):\n",
        "    ### START YOUR CODE HERE ###\n",
        "    # Implement a class for embedding layer here\n",
        "    def __init__(self,\n",
        "                vocab_size: int,\n",
        "                 embed_dim: int) -> None:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "        vocab_size (int) -- size of vocabulary\n",
        "        embed_dim (int) -- dimension of embeddings\n",
        "        \"\"\"\n",
        "        ...\n",
        "\n",
        "    def forward(self,\n",
        "                x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "        x: input vector\n",
        "\n",
        "        Returns:\n",
        "        out: embedding vector\n",
        "        \"\"\"\n",
        "        ...\n",
        "    ### END YOUR CODE HERE"
      ],
      "metadata": {
        "id": "1YdzhVisX_yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformers"
      ],
      "metadata": {
        "id": "cSy64WAocR36"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Positional encoding\n",
        "\n",
        "In order for the model to make sense of the sentence, it needs to know two things about the each word.\n",
        "* What does the word mean?\n",
        "* What is the position of the word in the sentence.\n",
        "\n",
        "In the original Transformer paper [(Vaswani et al., 2017)](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf), the author used 2 below functions to create positional encoding. On odd time steps a cosine function is used and in even time steps a sine function is used.\n",
        "\n",
        "$\n",
        "PE_{pos,2i} = sin\\left(\\frac{pos}{(10^5)^{\\frac{2i}{d_\\text{model} }}}\\right)\n",
        "$\n",
        "\n",
        "$\n",
        "PE_{pos,2i+1} = cos\\left(\\frac{pos}{(10^5)^{\\frac{2i}{d_\\text{model} }}}\\right)\n",
        "$\n",
        "\n",
        "\n",
        "Positinal embedding will **generate a matrix of similar to embedding matrix**. It will create a matrix of dimension sequence length `x` embedding dimension. For each token in sequence, we will find the embedding vector which is of dimension 1 x 512 and it is added with the correspondng positional vector which is of dimension 1 x 512 to get 1 x 512 dim out for each word/token.\n",
        "\n",
        "For example, if we have batch size of 32 and seq length of 10 and let embedding dimension be 512. Then we will have embedding vector of dimension 32 x 10 x 512. Similarly we will have positional encoding vector of dimension 32 x 10 x 512. Then we add both.\n",
        "\n",
        "![](https://aiml.com/wp-content/uploads/2023/09/example_of_positional_encoding_in_transformers.png)\n",
        "\n",
        "whereas:\n",
        "- `pos` refers to order in the sentence\n",
        "- `i`  refers to position along embedding vector dimension\n"
      ],
      "metadata": {
        "id": "FGP_BcSNblz_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTdFCd5CalHz"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(nn.Module):\n",
        "    def __init__(self,\n",
        "                 max_seq_len: int,\n",
        "                 embed_model_dim: int) -> None:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "        seq_len (int) -- length of input sequence\n",
        "        embed_model_dim (int) -- demension of embedding\n",
        "        \"\"\"\n",
        "        super(PositionalEmbedding, self).__init__()\n",
        "        self.embed_dim = embed_model_dim\n",
        "\n",
        "        pe = torch.zeros(max_seq_len, self.embed_dim)\n",
        "        for pos in range(max_seq_len):\n",
        "            for i in range(0, self.embed_dim, 2):\n",
        "                ### START YOUR CODE HERE ###\n",
        "\n",
        "                # Implement 2 positional encodings function (PE_{pos, 2i} & PE_{pos_{2i+1}}) here\n",
        "                # PE_{pos,2i} = sin\\left(\\frac{pos}{(10^5)^{\\frac{2i}{d_\\text{model} }}}\\right)\n",
        "                # PE_{pos,2i+1} = cos\\left(\\frac{pos}{(10^5)^{\\frac{2i}{d_\\text{model} }}}\\right)\n",
        "\n",
        "                pe[pos, i] = ...\n",
        "                pe[pos, i + 1] = ...\n",
        "\n",
        "                ### END YOUR CODE HERE ###\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "\n",
        "    def forward(self,\n",
        "                x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "        x: input vector\n",
        "\n",
        "        Returns:\n",
        "        x: output\n",
        "        \"\"\"\n",
        "        # Make embeddings relatively larger\n",
        "        x = x * math.sqrt(self.embed_dim)\n",
        "        # Add constant to embedding\n",
        "        seq_len = x.size(1)\n",
        "        x = x + torch.autograd.Variable(self.pe[:,:seq_len], requires_grad=False)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Self-attention & Multi-head attention\n",
        "\n",
        "***What is self attention?***\n",
        "\n",
        "Suppose we have a sentence `Dog is crossing the street because it saw the kitchen`. What does it refers to here? It's easy to understand for the humans that it is Dog. But not for the machines.\n",
        "\n",
        "As model proceeses each word, self attention allows it to look at other positions in the input sequence for clues. It will creates a vector based on dependency of each word with the other.\n",
        "\n",
        "\n",
        "Let us go through a step by step illustration of self attention.\n",
        "\n",
        "* **Step 1:** The first step in calculating self-attention is to create three vectors from each of the encoder’s input vectors (in this case, the embedding of each word). So for each word, we create a Query vector, a Key vector, and a Value vector. Each of the vector will be of dimension 1x64.\n",
        "\n",
        "Since we have a multihead attention we will have 8 self attention heads.I will explain the code with 8 attention head in mind.\n",
        "\n",
        "**How key,queries and values can be created?**\n",
        "\n",
        "We will have a key matrix,query matrix and a value matrix to generate key, query and value.\n",
        "These matrixes are learned during training.\n",
        "\n",
        "\n",
        "* **Step 2:**  Second step is to calculate the score. ie, we will multiply query marix with key matrix. [Q x K.t]\n",
        "\n",
        "\n",
        "\n",
        "* **Step 3:** Now divide the output matrix with square root of dimension of key matrix and then apply Softmax over it.\n",
        "\n",
        "\n",
        "* **Step 4:** Then this gets multiply it with value matrix.\n",
        "\n",
        "\n",
        "* **Step 5:** Once we have this we will pass this through a linear layer. This forms the output of multihead attention."
      ],
      "metadata": {
        "id": "Vjh8Y_LJZ1Pf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 512\n",
        "num_heads = 8\n",
        "\n",
        "multihead_attn = nn.MultiheadAttention(embed_dim, num_heads)\n",
        "multihead_attn"
      ],
      "metadata": {
        "id": "j2khzXA1aROJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "197f92c8-5c2e-4f1e-adfd-ce85c8ecf9d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiheadAttention(\n",
              "  (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self,\n",
        "                 embed_dim: int = 512,\n",
        "                 n_heads: int = 8) -> None:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "        embed_dim: dimension of embeding vector output\n",
        "        n_heads: number of self attention heads\n",
        "        \"\"\"\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "\n",
        "        self.embed_dim = embed_dim # dim = 512\n",
        "        self.n_heads = n_heads # dim = 8\n",
        "\n",
        "        # dim = 512/8 = 64\n",
        "        # Dach key,query, value will be of 64 dimensions\n",
        "        self.single_head_dim = int(self.embed_dim / self.n_heads)\n",
        "\n",
        "        # key, query and value matrices\n",
        "        # 64 x 64\n",
        "        self.query_matrix = nn.Linear(self.single_head_dim , self.single_head_dim ,bias=False)  # single key matrix for all 8 keys #512x512\n",
        "        self.key_matrix = nn.Linear(self.single_head_dim  , self.single_head_dim, bias=False)\n",
        "        self.value_matrix = nn.Linear(self.single_head_dim ,self.single_head_dim , bias=False)\n",
        "        self.out = nn.Linear(self.n_heads*self.single_head_dim ,self.embed_dim)\n",
        "\n",
        "    def forward(self,\n",
        "                key: torch.Tensor,\n",
        "                query: torch.Tensor,\n",
        "                value: torch.Tensor,\n",
        "                mask: torch.Tensor = None) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "        key : key vector\n",
        "        query : query vector\n",
        "        value : value vector\n",
        "        mask: mask for decoder\n",
        "\n",
        "        Returns:\n",
        "        Output vector from multihead attention\n",
        "        batch_size x sequence_length x embedding_dim = dim: 32 x 10 x 512\n",
        "        \"\"\"\n",
        "        batch_size = key.size(0)\n",
        "        seq_length = key.size(1)\n",
        "\n",
        "        # Query dimension can change in decoder during inference.\n",
        "        # So we cant take general seq_length\n",
        "        seq_length_query = query.size(1)\n",
        "\n",
        "        # 32x10x512\n",
        "        key = key.view(batch_size, seq_length, self.n_heads, self.single_head_dim)  #batch_size x sequence_length x n_heads x single_head_dim = (32x10x8x64)\n",
        "        query = query.view(batch_size, seq_length_query, self.n_heads, self.single_head_dim) #(32x10x8x64)\n",
        "        value = value.view(batch_size, seq_length, self.n_heads, self.single_head_dim) #(32x10x8x64)\n",
        "\n",
        "        k = self.key_matrix(key)       # (32x10x8x64)\n",
        "        q = self.query_matrix(query)\n",
        "        v = self.value_matrix(value)\n",
        "\n",
        "        q = q.transpose(1,2)  # (batch_size, n_heads, seq_len, single_head_dim)    # (32 x 8 x 10 x 64)\n",
        "        k = k.transpose(1,2)  # (batch_size, n_heads, seq_len, single_head_dim)\n",
        "        v = v.transpose(1,2)  # (batch_size, n_heads, seq_len, single_head_dim)\n",
        "\n",
        "        # computes attention\n",
        "        # adjust key for matrix multiplication\n",
        "        k_adjusted = k.transpose(-1,-2)  #(batch_size, n_heads, single_head_dim, seq_ken)  #(32 x 8 x 64 x 10)\n",
        "        product = torch.matmul(q, k_adjusted)  #(32 x 8 x 10 x 64) x (32 x 8 x 64 x 10) = #(32x8x10x10)\n",
        "\n",
        "\n",
        "        # fill those positions of product matrix as (-1e20) where mask positions are 0\n",
        "        if mask is not None:\n",
        "             product = product.masked_fill(mask == 0, float(\"-1e20\"))\n",
        "\n",
        "        #divising by square root of key dimension\n",
        "        product = product / math.sqrt(self.single_head_dim) # / sqrt(64)\n",
        "\n",
        "        #applying softmax\n",
        "        scores = F.softmax(product, dim=-1)\n",
        "\n",
        "        #mutiply with value matrix\n",
        "        scores = torch.matmul(scores, v)  ##(32x8x 10x 10) x (32 x 8 x 10 x 64) = (32 x 8 x 10 x 64)\n",
        "\n",
        "        #concatenated output\n",
        "        concat = scores.transpose(1,2).contiguous().view(batch_size, seq_length_query, self.single_head_dim*self.n_heads)  # (32x8x10x64) -> (32x10x8x64)  -> (32,10,512)\n",
        "\n",
        "        output = self.out(concat) #(32,10,512) -> (32,10,512)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "E9C97m2o6oAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer block\n"
      ],
      "metadata": {
        "id": "FvTJOUGXdonj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self,\n",
        "                 embed_dim: int,\n",
        "                 expansion_factor: int = 4,\n",
        "                 n_heads: int = 8) -> None:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "        embed_dim (int) -- Dimension embedding\n",
        "        expansion_factor (int) -- Factor which determines output dimension of linear layer\n",
        "        n_heads (int) -- Number of attention heads\n",
        "        \"\"\"\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.attention = MultiHeadAttention(embed_dim, n_heads)\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.norm2 = nn.LayerNorm(embed_dim)\n",
        "\n",
        "        # Feed forward network (Fully connected layer)\n",
        "        self.feed_forward = nn.Sequential(\n",
        "                          nn.Linear(embed_dim,\n",
        "                                    expansion_factor*embed_dim),\n",
        "                          nn.ReLU(),\n",
        "                          nn.Linear(expansion_factor*embed_dim,\n",
        "                                    embed_dim)\n",
        "        )\n",
        "\n",
        "        self.dropout1 = nn.Dropout(0.2)\n",
        "        self.dropout2 = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self,\n",
        "                key: torch.Tensor,\n",
        "                query: torch.Tensor,\n",
        "                value: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "        key -- Key vector\n",
        "        query -- Query vector\n",
        "        value -- Value vector\n",
        "\n",
        "        Returns:\n",
        "        (torch.Tensor) -- Output of Transformer block after passing data to the model\n",
        "        \"\"\"\n",
        "\n",
        "        attention_out = self.attention(key, query, value)  #32x10x512\n",
        "        attention_residual_out = attention_out + value  #32x10x512\n",
        "        norm1_out = self.dropout1(self.norm1(attention_residual_out)) #32x10x512\n",
        "\n",
        "        feed_fwd_out = self.feed_forward(norm1_out) #32x10x512 -> #32x10x2048 -> 32x10x512\n",
        "        feed_fwd_residual_out = feed_fwd_out + norm1_out #32x10x512\n",
        "        norm2_out = self.dropout2(self.norm2(feed_fwd_residual_out)) #32x10x512\n",
        "\n",
        "        return norm2_out"
      ],
      "metadata": {
        "id": "FmDQ5Lvod0E3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder\n",
        "\n",
        "Ok, now a sudden question can strike your mind. What is this mask used for? Don't worry we will go through it once we are talking about the decoder.\n",
        "\n",
        "![](https://www.researchgate.net/profile/Ehsan-Amjadian/publication/352239001/figure/fig1/AS:1033334390013952@1623377525434/Detailed-view-of-a-transformer-encoder-block-It-first-passes-the-input-through-an.jpg)\n",
        "\n",
        "\n",
        "\n",
        "In the encoder section -\n",
        "\n",
        "**Step 1:** First input(padded tokens corresponding to the sentence) get passes through embedding layer and positional encoding layer.\n",
        "\n",
        "\n",
        "**Step 2:** As discussed above it will passed through the multihead attention layer and creates useful representational matrix as output.\n",
        "\n",
        "**Step 3:** Next we have a normalization and residual connection. The output from multihead attention is added with its input and then normalized.\n",
        "\n",
        "**Step 4:** Next we have a feed forward layer and a then normalization layer with residual connection from input(input of feed forward layer) where we passes the output after normalization though it and finally gets the output of encoder."
      ],
      "metadata": {
        "id": "5UGLnuiKU3-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 seq_len,\n",
        "                 vocab_size,\n",
        "                 embed_dim,\n",
        "                 num_layers=2,\n",
        "                 expansion_factor=4,\n",
        "                 n_heads=8) -> None:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "        seq_len (int) -- length of input sequence\n",
        "        embed_dim (int) -- dimension of embedding\n",
        "        num_layers (int) -- number of encoder layers\n",
        "        expansion_factor (int) -- factor which determines number of linear layers in feed forward layer\n",
        "        n_heads (int) number of heads in multihead attention\n",
        "        \"\"\"\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "\n",
        "        self.embedding_layer = Embedding(vocab_size, embed_dim)\n",
        "        self.positional_encoder = PositionalEmbedding(seq_len, embed_dim)\n",
        "\n",
        "        self.layers = nn.ModuleList(\n",
        "            [\n",
        "                TransformerBlock(embed_dim, expansion_factor, n_heads)\n",
        "                for i in range(num_layers)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def forward(self,\n",
        "                x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward passing\n",
        "\n",
        "        Args:\n",
        "        x (torch.Tensor) -- Input tensor\n",
        "\n",
        "        Returns:\n",
        "        (torch.Tensor) -- Model's output after being forward-passed\n",
        "        \"\"\"\n",
        "        ### START YOUR CODE HERE ###\n",
        "        # Your task is to define a pipeline for forward passing process\n",
        "        # to receive a tensor vector and return a tensor encoded vector\n",
        "        # x -> embedding_layer -> positional_encoder -> n Transformer layers -> output\n",
        "\n",
        "        ...\n",
        "\n",
        "        ### END YOUR CODE HERE ###"
      ],
      "metadata": {
        "id": "YbK2K99nU6yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder\n",
        "\n",
        "\n",
        "Now we have gone through most parts of the encoder. Let us get in to the components of the decoder. We will use the output of encoder to generate key and value vectors for the decoder.There are two kinds of multi head attention in the decoder.One is the decoder attention and other is the encoder decoder attention. Don't worry we will go step by step.\n",
        "\n",
        "\n",
        "**Step 1:**\n",
        "\n",
        "First, the output gets passed through the embedding and positional encoding to create a embedding vector of dimension 1x512 corresponding to each word in the target sequence.\n",
        "\n",
        "\n",
        "\n",
        "**Step 2:**\n",
        "\n",
        "The embeddig output gets passed through a multihead attention layers as before(creating key,query and value matrixes from the target input) and produces an output vector. This time the major difference is that we uses a mask with multihead attention.\n",
        "\n",
        "**Why mask?**\n",
        "\n",
        "Mask is used because while creating attention of target words, we donot need a word to look in to the future words to check the dependency. ie, we already learned that why we create attention because we need to know contribution of each word with the other word. Since we are creating attention for words in target sequnce, we donot need a particular word to see the future words. For eg: in word \"I am a strudent\", we donot need the word \"a\" to look word \"student\".\n",
        "\n",
        "**Step 3:**\n",
        "\n",
        "As before we have a add and norm layer where we add with output of embedding with attention out and normalized it.\n",
        "\n",
        "\n",
        "**Step 4:**\n",
        "\n",
        "\n",
        "Next we have another multihead attention and then a add and norm layer. This multihead attention is called encoder-decorder multihead attention. For this multihead attention we create we create key and value vectors from the encoder output. Query is created from the output of previous decoder layer.\n",
        "\n",
        "\n",
        "Thus it is passed through a multihead atention (we used number of heads = 8) the through a Add and Norm layer. Here the output from previous encoder layer(ie previoud add and norm layer) gets added with encoder-decoder attention output and then normalized.\n",
        "\n",
        "**Step 5:**\n",
        "Next we have a feed forward layer(linear layer) with add and nom which is similar to that of present in the encoder.\n",
        "\n",
        "\n",
        "**Step 6:**\n",
        "Finally we create a linear layer with length equal to number of words in total target corpus and a softmax function with it to get probablity of each word."
      ],
      "metadata": {
        "id": "RJnBQJkJkTb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self,\n",
        "                 embed_dim,\n",
        "                 expansion_factor=4,\n",
        "                 n_heads=8) -> None:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "        embed_dim (int) -- Embedding dimension\n",
        "        expansion_factor (int) -- Factor which determines output dimension of linear layer\n",
        "        n_heads (int) -- Number of attention heads\n",
        "        \"\"\"\n",
        "        super(DecoderBlock, self).__init__()\n",
        "        self.attention = MultiHeadAttention(embed_dim,\n",
        "                                            n_heads=n_heads)\n",
        "        self.norm = nn.LayerNorm(embed_dim)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.transformer_block = TransformerBlock(embed_dim,\n",
        "                                                  expansion_factor,\n",
        "                                                  n_heads)\n",
        "\n",
        "    def forward(self,\n",
        "                key: torch.Tensor,\n",
        "                query: torch.Tensor,\n",
        "                x: torch.Tensor,\n",
        "                mask) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "        key (torch.Tensor) -- Key vector\n",
        "        query (torch.Tensor) -- Query vector\n",
        "        value (torch.Tensor) -- Value vector\n",
        "        mask (torch.Tensor) -- Mask to be given for multi head attention\n",
        "\n",
        "        Returns:\n",
        "        out (torch.Tensor) -- Output of transformer block\n",
        "        \"\"\"\n",
        "        # We need to pass mask mask only to attention\n",
        "        attention = self.attention(x,\n",
        "                                   x,\n",
        "                                   x,\n",
        "                                   mask=mask) #32x10x512\n",
        "        value = self.dropout(self.norm(attention + x))\n",
        "        out = self.transformer_block(key, query, value)\n",
        "        return out"
      ],
      "metadata": {
        "id": "AveORc13d6Ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, target_vocab_size, embed_dim, seq_len, num_layers=2, expansion_factor=4, n_heads=8):\n",
        "        super(TransformerDecoder, self).__init__()\n",
        "        \"\"\"\n",
        "        Args:\n",
        "           target_vocab_size: vocabulary size of taget\n",
        "           embed_dim: dimension of embedding\n",
        "           seq_len : length of input sequence\n",
        "           num_layers: number of encoder layers\n",
        "           expansion_factor: factor which determines number of linear layers in feed forward layer\n",
        "           n_heads: number of heads in multihead attention\n",
        "\n",
        "        \"\"\"\n",
        "        self.word_embedding = nn.Embedding(target_vocab_size, embed_dim)\n",
        "        self.positional_embedding = PositionalEmbedding(seq_len, embed_dim)\n",
        "\n",
        "        self.layers = nn.ModuleList(\n",
        "            [\n",
        "                DecoderBlock(embed_dim, expansion_factor=4, n_heads=8)\n",
        "                for _ in range(num_layers)\n",
        "            ]\n",
        "        )\n",
        "        self.fc_out = nn.Linear(embed_dim, target_vocab_size)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self,\n",
        "                x: torch.Tensor,\n",
        "                encoder_out: torch.Tensor,\n",
        "                mask: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        \"\"\"\n",
        "        Args:\n",
        "        x (torch.Tensor) -- Input vector from target\n",
        "        encoder_out (torch.Tensor) -- Output from encoder layer\n",
        "        trg_mask (torch.Tensor) -- Mask for decoder self attention\n",
        "\n",
        "        Returns:\n",
        "        (torch.Tensor) -- Output tensor\n",
        "        \"\"\"\n",
        "        ### START YOUR CODE HERE ###\n",
        "        # Create a workflow from input to output for Decoder layer\n",
        "        # x -> word_embedding -> positional_embedding -> dropout -> Decoder layers -> output\n",
        "\n",
        "        ...\n",
        "\n",
        "        ### END YOUR CODE HERE ###"
      ],
      "metadata": {
        "id": "oIg9AiZ3bg8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer model\n",
        "\n",
        "Finally we will arrange all submodules and creates the entire tranformer architecture."
      ],
      "metadata": {
        "id": "2pamjm7ilqmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 embed_dim: int,\n",
        "                 source_vocab_size: int,\n",
        "                 target_vocab_size: int,\n",
        "                 seq_length: int,\n",
        "                 num_layers: int = 2,\n",
        "                 expansion_factor: int = 4,\n",
        "                 n_heads: int = 8):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "        embed_dim (int) -- Embedding dimension\n",
        "        source_vocab_size (int) -- Input's vocabulary size\n",
        "        target_vocab_size (int) -- Target's vocabulary size\n",
        "        seq_length (int) -- Length of input sequence\n",
        "        num_layers (int) -- Number of encoder layers\n",
        "        expansion_factor (int) -- Factor which determines number of linear layers in feed forward layer\n",
        "        n_heads (int) -- Number of heads in multihead attention\n",
        "        \"\"\"\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.target_vocab_size = target_vocab_size\n",
        "\n",
        "        ### START YOUR CODE HERE ###\n",
        "        # Declare encoder and decoder components\n",
        "\n",
        "        self.encoder = ...\n",
        "        self.decoder = ...\n",
        "\n",
        "        ### END YOUR CODE HERE ###\n",
        "\n",
        "    def make_target_mask(self,\n",
        "                      target: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "        target (torch.Tensor) -- Target sequence\n",
        "\n",
        "        Returns:\n",
        "        target_mask: target mask\n",
        "        \"\"\"\n",
        "        batch_size, target_len = target.shape\n",
        "        # Returns the lower triangular part of matrix filled with ones\n",
        "        target_mask = torch.tril(\n",
        "            torch.ones((target_len, target_len))\n",
        "            ).expand(batch_size, 1, target_len, target_len)\n",
        "        return target_mask\n",
        "\n",
        "    def decode(self,\n",
        "               source: torch.Tensor,\n",
        "               target: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "        source (torch.Tensor) -- Input to encoder\n",
        "        target (torch.Tensor) -- Input to decoder\n",
        "\n",
        "        Returns:\n",
        "        (torch.Tensor) -- Returns final prediction of sequence\n",
        "        \"\"\"\n",
        "        target_mask = self.make_target_mask(target)\n",
        "        enc_out = self.encoder(source)\n",
        "        out_labels = []\n",
        "        batch_size,seq_len = source.shape[0],source.shape[1]\n",
        "        out = target\n",
        "        for i in range(seq_len): #10\n",
        "            out = self.decoder(out,enc_out,target_mask) #bs x seq_len x vocab_dim\n",
        "            # Take the last token\n",
        "            out = out[:,-1,:]\n",
        "            out = out.argmax(-1)\n",
        "            out_labels.append(out.item())\n",
        "            out = torch.unsqueeze(out,axis=0)\n",
        "\n",
        "        return out_labels\n",
        "\n",
        "    def forward(self,\n",
        "                source: torch.Tensor,\n",
        "                target: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "        source (torch.Tensor) -- Input to encoder\n",
        "        target (torch.Tensor) -- Input to decoder\n",
        "\n",
        "        Returns:\n",
        "        (torch.Tensor) -- Vector which returns probabilities of each target word\n",
        "        \"\"\"\n",
        "        target_mask = self.make_target_mask(target)\n",
        "        encoder_out = self.encoder(source)\n",
        "        outputs = self.decoder(target, encoder_out, target_mask)\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "bffqzXAZlr19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NMT data"
      ],
      "metadata": {
        "id": "8gSYyH6eiiXe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXMRz12JHXJ0"
      },
      "outputs": [],
      "source": [
        "dataset = datasets.load_dataset(\"bentrevett/multi30k\")\n",
        "\n",
        "train_data, valid_data, test_data = (\n",
        "    dataset[\"train\"],\n",
        "    dataset[\"validation\"],\n",
        "    dataset[\"test\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBVPLCHGHXJ0",
        "outputId": "f6928f14-28d1-49c6-f59a-192b876f4836",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'en': 'Two young, White males are outside near many bushes.',\n",
              " 'de': 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.'}"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ],
      "source": [
        "train_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCS0wd5ZHXJ0"
      },
      "outputs": [],
      "source": [
        "en_nlp = spacy.load(\"en_core_web_sm\")\n",
        "de_nlp = spacy.load(\"de_core_news_sm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRBC_kI1HXJ0"
      },
      "source": [
        "We can call the tokenizer for each spaCy model using the `.tokenizer` method, which accepts a string and returns a sequence of `Token` objects. We can get the string from the token object using the `text` attribute.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czfWsP1mHXJ0",
        "outputId": "d5396683-c8a4-4bb1-fffe-e27b8098f7f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['What', 'a', 'lovely', 'day', 'it', 'is', 'today', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "string = \"What a lovely day it is today!\"\n",
        "\n",
        "[token.text for token in en_nlp.tokenizer(string)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7N849BaHXJ0"
      },
      "outputs": [],
      "source": [
        "def tokenize_example(example, en_nlp, de_nlp, max_length, lower, sos_token, eos_token):\n",
        "    en_tokens = [token.text for token in en_nlp.tokenizer(example[\"en\"])][:max_length]\n",
        "    de_tokens = [token.text for token in de_nlp.tokenizer(example[\"de\"])][:max_length]\n",
        "    if lower:\n",
        "        en_tokens = [token.lower() for token in en_tokens]\n",
        "        de_tokens = [token.lower() for token in de_tokens]\n",
        "    en_tokens = [sos_token] + en_tokens + [eos_token]\n",
        "    de_tokens = [sos_token] + de_tokens + [eos_token]\n",
        "    return {\"en_tokens\": en_tokens, \"de_tokens\": de_tokens}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "5d05eefdcd0c4567acaa1c4be7590b87",
            "f1180baf36b54ac4a50667f782e6008a",
            "56ed3e86fd234c309c4ecc28d29e33a5",
            "063fc7d5e28942918ce597e4b6233e6b",
            "56d445561c4b4e8fba6a6bd0f4c43171",
            "d5620afe036b446bb8ed5f6b13d5f956",
            "6aad1b0fc9af47a78619127ebe9b8562",
            "09616dd31c214738ad1070fdc2ad1781",
            "72011e26bad94cf590e45feb0c7b06c0",
            "d561427834004682b71d45ed961dd0be",
            "b2e5ebd4cb7f471e83707b30456e3ebd",
            "fad3ce6eb871406a8e0f1c66d4c045ef",
            "701d2cd3e2a647c284940bb785668843",
            "64cdf0965d4046a48e0f5e42f6a5bc69",
            "6f4fa927b0a544bfb7315dee3c217d37",
            "bc196eacf9f54f8898e781e4099e5328",
            "564243b509d84d1c9d0deb19d9d18a4e",
            "562507f708c046deb029a37737db8984",
            "de658929f8c74c558befac2f0e095748",
            "9e1885d9c5fc48e8971a4f4adda55f3f",
            "810a7b43f411476fb626e6696dc03742",
            "f3590849acd2411e88839fcf41b770bb"
          ],
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "pdQfZcCHHXJ1",
        "outputId": "5fab6829-3cf8-45d4-90e6-3a06331090d5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1014 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d05eefdcd0c4567acaa1c4be7590b87"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fad3ce6eb871406a8e0f1c66d4c045ef"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "max_length = 1_000\n",
        "lower = True\n",
        "sos_token = \"<sos>\"\n",
        "eos_token = \"<eos>\"\n",
        "\n",
        "fn_kwargs = {\n",
        "    \"en_nlp\": en_nlp,\n",
        "    \"de_nlp\": de_nlp,\n",
        "    \"max_length\": max_length,\n",
        "    \"lower\": lower,\n",
        "    \"sos_token\": sos_token,\n",
        "    \"eos_token\": eos_token,\n",
        "}\n",
        "\n",
        "train_data = train_data.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
        "valid_data = valid_data.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
        "test_data = test_data.map(tokenize_example, fn_kwargs=fn_kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkdKi-CJHXJ1",
        "outputId": "95dd99df-cc6a-4707-8c17-b07dc3c8435e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'en': 'Two young, White males are outside near many bushes.',\n",
              " 'de': 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.',\n",
              " 'en_tokens': ['<sos>',\n",
              "  'two',\n",
              "  'young',\n",
              "  ',',\n",
              "  'white',\n",
              "  'males',\n",
              "  'are',\n",
              "  'outside',\n",
              "  'near',\n",
              "  'many',\n",
              "  'bushes',\n",
              "  '.',\n",
              "  '<eos>'],\n",
              " 'de_tokens': ['<sos>',\n",
              "  'zwei',\n",
              "  'junge',\n",
              "  'weiße',\n",
              "  'männer',\n",
              "  'sind',\n",
              "  'im',\n",
              "  'freien',\n",
              "  'in',\n",
              "  'der',\n",
              "  'nähe',\n",
              "  'vieler',\n",
              "  'büsche',\n",
              "  '.',\n",
              "  '<eos>']}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "train_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7lceQS7HXJ1"
      },
      "outputs": [],
      "source": [
        "min_freq = 2\n",
        "unk_token = \"<unk>\"\n",
        "pad_token = \"<pad>\"\n",
        "\n",
        "special_tokens = [\n",
        "    unk_token,\n",
        "    pad_token,\n",
        "    sos_token,\n",
        "    eos_token,\n",
        "]\n",
        "\n",
        "en_vocab = torchtext.vocab.build_vocab_from_iterator(\n",
        "    train_data[\"en_tokens\"],\n",
        "    min_freq=min_freq,\n",
        "    specials=special_tokens,\n",
        ")\n",
        "\n",
        "de_vocab = torchtext.vocab.build_vocab_from_iterator(\n",
        "    train_data[\"de_tokens\"],\n",
        "    min_freq=min_freq,\n",
        "    specials=special_tokens,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rcn7UiGcHXJ1",
        "outputId": "acb63f56-4c52-49fe-8975-d776df1d84f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5893, 7853)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "len(en_vocab), len(de_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2iEyi-bHXJ1",
        "outputId": "ca458f69-341d-4faf-ab38-f855e3fdc344",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>', '<pad>', '<sos>', '<eos>', 'a', '.', 'in', 'the', 'on', 'man']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "en_vocab.get_itos()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQVmbLI9HXJ1",
        "outputId": "3fc0b2f5-4a54-4ac8-fa0b-35568f294d64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>', '<pad>', '<sos>', '<eos>', '.', 'ein', 'einem', 'in', 'eine', ',']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "de_vocab.get_itos()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoY5hHUNHXJ5"
      },
      "outputs": [],
      "source": [
        "unk_index = en_vocab[unk_token]\n",
        "pad_index = en_vocab[pad_token]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EN9hrwlYHXJ5"
      },
      "outputs": [],
      "source": [
        "en_vocab.set_default_index(unk_index)\n",
        "de_vocab.set_default_index(unk_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJyVYf2NHXJ6",
        "outputId": "8e5cd08d-8e22-4849-e940-1f9adc61f224",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "en_vocab[\"The\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ayMedecHXJ6",
        "outputId": "91e36151-05d7-48eb-ae3e-f6616f2dc3d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<unk>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "en_vocab.get_itos()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIfpwDPQHXJ6"
      },
      "outputs": [],
      "source": [
        "tokens = [\"i\", \"love\", \"watching\", \"crime\", \"shows\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lE1kO0WRHXJ6",
        "outputId": "6f1cfcff-408c-499a-b711-c8b1ce64a85c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[956, 2169, 173, 0, 821]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "en_vocab.lookup_indices(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51_nL09vHXJ6"
      },
      "source": [
        "Conversely, we can use the `lookup_tokens` method to convert a list of indices back into tokens using the vocabulary. Notice how the original \"crime\" token is now an `<unk>` token. There is no way to tell what the original sequence of tokens was.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1kIpKvMHXJ6",
        "outputId": "fcbf4240-aee9-41af-bd08-04c03175cd93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'love', 'watching', '<unk>', 'shows']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "en_vocab.lookup_tokens(en_vocab.lookup_indices(tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MD0NFMtBHXJ6"
      },
      "source": [
        "Hopefully we've now got the gist of how the `torchtext.Vocab` class works. Time to put it into action!\n",
        "\n",
        "Just like our `tokenize_example`, we create a `numericalize_example` function which we'll use with the `map` method of our dataset. This will \"numericalize\" (a fancy way of saying convert tokens to indices) our tokens in each example using the vocabularies and return the result into new \"en_ids\" and \"de_ids\" features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2iIfWMhHXJ6"
      },
      "outputs": [],
      "source": [
        "def numericalize_example(example, en_vocab, de_vocab):\n",
        "    en_ids = en_vocab.lookup_indices(example[\"en_tokens\"])\n",
        "    de_ids = de_vocab.lookup_indices(example[\"de_tokens\"])\n",
        "    return {\"en_ids\": en_ids, \"de_ids\": de_ids}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZm96LBuHXJ6"
      },
      "source": [
        "We apply the `numericalize_example` function, passing our vocabularies in the `fn_kwargs` dictionary to the `fn_kwargs` argument.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "a168d488bb1048609076acfff2a4abf7",
            "9b328db147b84c5e87d5b698b207d2bc",
            "5356139adb1e4478a64b8da704109764",
            "0706c48723ba49c9a7df4b00a50a81b2",
            "5cc8d644003f4c5d801a66ee92f98f11",
            "76a42bc5e08c4bb5821568007d0eb74b",
            "1921d8d647d44acb9a1f6b5cf952eaf5",
            "00201db6c377498fb60026f9bfc583f5",
            "06ca150df07346bf89f83026b07ab14f",
            "21fe7553aeea4fbdad1f4db3c1496103",
            "681d243143f449fb9d703674265fc6d7",
            "f3616e3da2214211a0ffb044b71dd6ac",
            "994115f7261842a7a53a9fcc1d97927e",
            "46607ae59b634ce8b6e09ca685e5203f",
            "2b9a3f50cf634e2c8bccf92c2819c9dc",
            "f8769cffd0b146ddbb4c30aaecd79115",
            "20d86517fffd4d40966dbe78a68a6b52",
            "aa5f8604382346daa843eb60b1dc81a8",
            "e340b4bfa2cf40d8a126fd453e6bc2a4",
            "532aacbf72344a9b83c1d518c2f7993f",
            "91c50424b4294ab393d43023a316ccac",
            "631bc49e160346c18d25f0a5299554d9",
            "2e0954365a6f44ca93481f854992f865",
            "490a6331e7b348ae8ac3b51fe5acff8f",
            "cdcceabc3b974c7c9c53d06cf0813980",
            "dd8246567bd14493b328f8c9fa2f7f35",
            "d7235d43067f423ea95c060aeb3e2f47",
            "2794fb9a823f4e4ca3cf550c4d48d47c",
            "2720cace0a774d5da4009a9d71e4850c",
            "64783c326a5e43beaf5794b84017e613",
            "3ceafe192db9490bbf627158dca65922",
            "1d60a269d2674f0186bd003928f62199",
            "4dd740090ed94373b3f72639e64c2924"
          ],
          "base_uri": "https://localhost:8080/",
          "height": 113
        },
        "id": "flEG2EE-HXJ6",
        "outputId": "a6223eb0-e4fc-482d-a0a5-282175abf053"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/29000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a168d488bb1048609076acfff2a4abf7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1014 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3616e3da2214211a0ffb044b71dd6ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e0954365a6f44ca93481f854992f865"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "fn_kwargs = {\"en_vocab\": en_vocab, \"de_vocab\": de_vocab}\n",
        "\n",
        "train_data = train_data.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
        "valid_data = valid_data.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
        "test_data = test_data.map(numericalize_example, fn_kwargs=fn_kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7v-ohYpmHXJ6"
      },
      "source": [
        "Checking an example, we can see that it has the two new features: \"en_ids\" and \"de_ids\", both a list of integers representing their indices in the respective vocabulary.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-NboBSCHXJ6",
        "outputId": "a11d1bfa-5aab-4e02-cd71-0d6ede0475f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'en': 'Two young, White males are outside near many bushes.',\n",
              " 'de': 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.',\n",
              " 'en_tokens': ['<sos>',\n",
              "  'two',\n",
              "  'young',\n",
              "  ',',\n",
              "  'white',\n",
              "  'males',\n",
              "  'are',\n",
              "  'outside',\n",
              "  'near',\n",
              "  'many',\n",
              "  'bushes',\n",
              "  '.',\n",
              "  '<eos>'],\n",
              " 'de_tokens': ['<sos>',\n",
              "  'zwei',\n",
              "  'junge',\n",
              "  'weiße',\n",
              "  'männer',\n",
              "  'sind',\n",
              "  'im',\n",
              "  'freien',\n",
              "  'in',\n",
              "  'der',\n",
              "  'nähe',\n",
              "  'vieler',\n",
              "  'büsche',\n",
              "  '.',\n",
              "  '<eos>'],\n",
              " 'en_ids': [2, 16, 24, 15, 25, 778, 17, 57, 80, 202, 1312, 5, 3],\n",
              " 'de_ids': [2, 18, 26, 253, 30, 84, 20, 88, 7, 15, 110, 7647, 3171, 4, 3]}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "train_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgw_xGn_HXJ6",
        "outputId": "8de84731-4dc4-48a2-f408-3f9158016723",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos>',\n",
              " 'two',\n",
              " 'young',\n",
              " ',',\n",
              " 'white',\n",
              " 'males',\n",
              " 'are',\n",
              " 'outside',\n",
              " 'near',\n",
              " 'many',\n",
              " 'bushes',\n",
              " '.',\n",
              " '<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "en_vocab.lookup_tokens(train_data[0][\"en_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcPsmqwVHXJ6"
      },
      "outputs": [],
      "source": [
        "data_type = \"torch\"\n",
        "format_columns = [\"en_ids\", \"de_ids\"]\n",
        "\n",
        "train_data = train_data.with_format(\n",
        "    type=data_type, columns=format_columns, output_all_columns=True\n",
        ")\n",
        "\n",
        "valid_data = valid_data.with_format(\n",
        "    type=data_type,\n",
        "    columns=format_columns,\n",
        "    output_all_columns=True,\n",
        ")\n",
        "\n",
        "test_data = test_data.with_format(\n",
        "    type=data_type,\n",
        "    columns=format_columns,\n",
        "    output_all_columns=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIetGHTJHXJ7",
        "outputId": "7aba68ac-eb79-40a8-f307-d65c785a1671",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'en_ids': tensor([   2,   16,   24,   15,   25,  778,   17,   57,   80,  202, 1312,    5,\n",
              "            3]),\n",
              " 'de_ids': tensor([   2,   18,   26,  253,   30,   84,   20,   88,    7,   15,  110, 7647,\n",
              "         3171,    4,    3]),\n",
              " 'en': 'Two young, White males are outside near many bushes.',\n",
              " 'de': 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.',\n",
              " 'en_tokens': ['<sos>',\n",
              "  'two',\n",
              "  'young',\n",
              "  ',',\n",
              "  'white',\n",
              "  'males',\n",
              "  'are',\n",
              "  'outside',\n",
              "  'near',\n",
              "  'many',\n",
              "  'bushes',\n",
              "  '.',\n",
              "  '<eos>'],\n",
              " 'de_tokens': ['<sos>',\n",
              "  'zwei',\n",
              "  'junge',\n",
              "  'weiße',\n",
              "  'männer',\n",
              "  'sind',\n",
              "  'im',\n",
              "  'freien',\n",
              "  'in',\n",
              "  'der',\n",
              "  'nähe',\n",
              "  'vieler',\n",
              "  'büsche',\n",
              "  '.',\n",
              "  '<eos>']}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "train_data[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Dataloader for Transformers to train and evaluate"
      ],
      "metadata": {
        "id": "IW-m1I432mF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### START YOUR CODE HERE ###\n",
        "# Your task is to build a dataloader to load train & test tensor\n",
        "# from the aforegiven dataset\n",
        "\n",
        "### END YOUR CODE HERE ###"
      ],
      "metadata": {
        "id": "OLvlgP5n3FaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apply model"
      ],
      "metadata": {
        "id": "2AN8OEzc9npU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define model"
      ],
      "metadata": {
        "id": "2ly6tX4i3DsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Hyperparameters configuration\n",
        "\n",
        "Try changing the following hyperparameters to:\n",
        "- Observe its effect on the model performance\n",
        "- Boost its performance on the given dataset\n",
        "\"\"\"\n",
        "source_vocab_size = 11\n",
        "target_vocab_size = 11\n",
        "num_layers = 6\n",
        "seq_length= 12\n",
        "embed_dim = 512\n",
        "expansion_factor = 4\n",
        "n_heads = 8"
      ],
      "metadata": {
        "id": "ad7hA-qR2-Wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Transformer(embed_dim=embed_dim,\n",
        "                    source_vocab_size=source_vocab_size,\n",
        "                    target_vocab_size=target_vocab_size,\n",
        "                    seq_length=seq_length,\n",
        "                    num_layers=num_layers,\n",
        "                    expansion_factor=expansion_factor,\n",
        "                    n_heads=n_heads)\n",
        "model"
      ],
      "metadata": {
        "id": "wlOpQfYa2pZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd6aa239-1ec9-479b-f0ed-8bd95235a176"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (encoder): TransformerEncoder(\n",
              "    (embedding_layer): Embedding(\n",
              "      (embed): Embedding(11, 512)\n",
              "    )\n",
              "    (positional_encoder): PositionalEmbedding()\n",
              "    (layers): ModuleList(\n",
              "      (0-5): 6 x TransformerBlock(\n",
              "        (attention): MultiHeadAttention(\n",
              "          (query_matrix): Linear(in_features=64, out_features=64, bias=False)\n",
              "          (key_matrix): Linear(in_features=64, out_features=64, bias=False)\n",
              "          (value_matrix): Linear(in_features=64, out_features=64, bias=False)\n",
              "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (feed_forward): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "        (dropout1): Dropout(p=0.2, inplace=False)\n",
              "        (dropout2): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (decoder): TransformerDecoder(\n",
              "    (word_embedding): Embedding(11, 512)\n",
              "    (positional_embedding): PositionalEmbedding()\n",
              "    (layers): ModuleList(\n",
              "      (0-5): 6 x DecoderBlock(\n",
              "        (attention): MultiHeadAttention(\n",
              "          (query_matrix): Linear(in_features=64, out_features=64, bias=False)\n",
              "          (key_matrix): Linear(in_features=64, out_features=64, bias=False)\n",
              "          (value_matrix): Linear(in_features=64, out_features=64, bias=False)\n",
              "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "        (transformer_block): TransformerBlock(\n",
              "          (attention): MultiHeadAttention(\n",
              "            (query_matrix): Linear(in_features=64, out_features=64, bias=False)\n",
              "            (key_matrix): Linear(in_features=64, out_features=64, bias=False)\n",
              "            (value_matrix): Linear(in_features=64, out_features=64, bias=False)\n",
              "            (out): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (feed_forward): Sequential(\n",
              "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "            (1): ReLU()\n",
              "            (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          )\n",
              "          (dropout1): Dropout(p=0.2, inplace=False)\n",
              "          (dropout2): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (fc_out): Linear(in_features=512, out_features=11, bias=True)\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model QA"
      ],
      "metadata": {
        "id": "TwZgCOuz41OD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# QA for model's forward passing\n",
        "start_of_string_token = 0\n",
        "end_of_string_token = 1\n",
        "\n",
        "src = torch.tensor([[start_of_string_token, 2, 5, 6, 4, 3, 9, 5, 2, 9, 10, end_of_string_token],\n",
        "                    [start_of_string_token, 2, 8, 7, 3, 4, 5, 6, 7, 2, 10, end_of_string_token]])\n",
        "target = torch.tensor([[start_of_string_token, 1, 7, 4, 3, 5, 9, 2, 8, 10, 9, end_of_string_token],\n",
        "                       [start_of_string_token, 1, 5, 6, 2, 4, 7, 6, 2, 8, 10, end_of_string_token]])\n",
        "out = model(src, target)\n",
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ql4sAHCE462s",
        "outputId": "606f28cf-690a-4b5a-df1f-101764db8df2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-120-e25e834bee75>:50: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = F.softmax(self.fc_out(x))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 12, 11])"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# QA for model's final decoding\n",
        "src = torch.tensor([[start_of_string_token, 2, 5, 6, 4, 3, 9, 5, 2, 9, 10, end_of_string_token]])\n",
        "trg = torch.tensor([[start_of_string_token]])\n",
        "out = model.decode(src, trg)\n",
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L221iX3r40dn",
        "outputId": "464b75f7-7dd1-435d-8a25-485068abb0c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-120-e25e834bee75>:50: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = F.softmax(self.fc_out(x))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model training"
      ],
      "metadata": {
        "id": "DqSq7X5l256H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Model training\n",
        "\"\"\"\n",
        "### START YOUR CODE HERE ###\n",
        "\n",
        "### END YOUR CODE HERE ###"
      ],
      "metadata": {
        "id": "zeZ9VS6D2lNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model evaluation"
      ],
      "metadata": {
        "id": "O5woMriu4VNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Model evaluation\n",
        "\"\"\"\n",
        "### START YOUR CODE HERE ###\n",
        "\n",
        "### END YOUR CODE HERE ###"
      ],
      "metadata": {
        "id": "nWr1AOdw4X1t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}